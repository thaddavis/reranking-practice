---
video_title: "Build a private R.A.G. Assistant with CrewAI, Ollama, & AgentOps"
video_url: "https://www.youtube.com/watch/MDb81aT0V4w"
---

00:00:00.000 [Music]
00:00:02.120 somewhere on our computer let's create a
00:00:04.440 folder where we will start our work for
00:00:07.040 example I'm creating a folder called our
00:00:09.400 project folder let's CD into it and open
00:00:13.240 it up with our code editor of choice I
00:00:16.680 will be using VSS code as we're in a
00:00:19.720 fresh folder building a fresh project
00:00:22.480 let's create our virtual environment
00:00:24.199 like so if you're unfamiliar with this
00:00:26.920 virtual environment stuff all we're
00:00:28.960 doing is configuring python to install
00:00:32.719 any third-party python packages related
00:00:35.040 to this project inside of this project
00:00:39.280 folder so that it doesn't affect any
00:00:41.680 other python projects on our
00:00:47.440 computer and if we run the UV init
00:00:51.960 command you should see uh python project
00:00:55.280 scaffolded for us here and with this
00:00:59.199 scaffolded UV project we get a little
00:01:03.000 hello.py script and this allows us to
00:01:06.880 smoke test everything is working and you
00:01:09.840 can see this little warning here this is
00:01:13.080 vs code asking us to confirm which
00:01:16.360 virtual environment we are working in
00:01:20.119 and this is the one we just created and
00:01:24.320 I like to remove this hello.py script
00:01:28.000 because we won't need it and and now
00:01:31.439 that we have all of that set up we can
00:01:35.520 add crei to our project folder like
00:01:42.479 so and after crei is downloaded we can
00:01:46.079 print out its version to confirm it's
00:01:48.040 working and you can see we're using
00:01:52.920 0.860 to scaffold a crew aai application
00:01:56.079 with the crew aai CLI we enter the
00:01:57.799 following command crew AI create crew
00:02:00.240 followed by the name of our project and
00:02:02.320 I'm going to use the name rag assistant
00:02:04.680 and you can see we're presented with a
00:02:05.920 menu that helps us set up this
00:02:07.240 autogenerated project and the provider
00:02:10.000 is the name of the company or group that
00:02:13.040 will provide the AI we want to use to us
00:02:16.480 so we're not going to use open AI we're
00:02:18.280 not going to use anthropic to mix it up
00:02:20.200 we're going to use
00:02:22.000 olama and AMA actually provides hundreds
00:02:25.760 of different models but you can see in
00:02:27.599 this menu it only allows us to select
00:02:29.440 two of them
00:02:30.720 so we'll be switching this model later
00:02:34.760 but for now let's just select llama 3.1
00:02:37.680 and you can see that uh another folder
00:02:41.680 has been created for us called ragor
00:02:43.800 assistant and let's CD into
00:02:47.640 it and open it with vs code and I know
00:02:53.120 this might seem strange that we just
00:02:55.760 created a project to create another
00:02:58.760 project within it but that's how this
00:03:01.680 works now that we're in this second
00:03:04.720 project folder let's make sure that its
00:03:06.840 virtual environment is set up correctly
00:03:08.720 so that whatever work we do doesn't
00:03:10.680 affect the outer project or any other
00:03:12.640 project that's sitting on our computer
00:03:15.239 so here I am just making sure the
00:03:19.519 virtual environment is set up correctly
00:03:32.000 and if we run this
00:03:34.510 [Music]
00:03:36.840 command we should be
00:03:39.680 good and yeah that looks great let's
00:03:42.640 take a quick look at this crew AI
00:03:44.519 project to get a feel for what's going
00:03:45.920 on so if we pop open this Source folder
00:03:48.000 we can see a config folder inside of it
00:03:50.519 this is where crew AI allows us to
00:03:52.480 configure the agents and tasks in our
00:03:56.319 application so here you can see we
00:03:59.360 currently have two agents A researcher
00:04:02.720 and an analyst and the tasks that we're
00:04:05.200 giving to them are to perform research
00:04:07.599 about a topic and then write a report on
00:04:10.879 said topic the way that we trigger this
00:04:14.760 application is by calling this run
00:04:17.639 function and here you can see the topic
00:04:19.798 that we're giving to our agents is AI
00:04:22.040 llms so I mentioned earlier we were
00:04:24.360 going to be using a different AMA model
00:04:27.479 not llama 3.1 so the way that we
00:04:31.520 customize this is by importing the llm
00:04:34.800 module from crew aai and here is how we
00:04:39.400 configure each agent to use not llama
00:04:42.479 3.1 but Gemma 2 Gemma 2 is another
00:04:46.720 open-source model that is provided not
00:04:49.600 by meta but by Google so it's small
00:04:52.440 enough to run on our computer and the
00:04:56.000 way that we're going to run it is by
00:04:58.759 using olama AMA is a super easy to use
00:05:02.600 tool you can download it at ama.com it
00:05:05.720 literally takes a minute or two to set
00:05:07.840 it up and run it and after you have Ama
00:05:10.280 running you can come over to a terminal
00:05:15.199 and
00:05:16.280 download the model that you want to run
00:05:19.680 by entering the AMA pull command and
00:05:22.560 after you write pull you write the model
00:05:25.039 ID that you want to
00:05:27.080 download and there we go so so now that
00:05:31.880 all of that is taken care of let's run
00:05:35.000 our crew AI application by entering the
00:05:37.759 crew AI run
00:05:44.360 command here is the report that was
00:05:47.840 generated so it looks like our
00:05:51.440 autogenerated crew aai application is
00:05:56.400 working now let's customize This
00:05:58.560 autogenerated Crew AI project and build
00:06:01.280 a little rag application the data that
00:06:04.120 we will perform rag against will be this
00:06:06.720 ebook published earlier this year by
00:06:09.120 Noel
00:06:10.919 Russell so let's add this ebook to the
00:06:14.280 knowledge folder of our crew AI project
00:06:17.240 for those who don't know Noel Russell is
00:06:19.039 an IRL AI influencer based in South
00:06:22.599 Florida she has worked at AWS IBM
00:06:26.840 Accenture and Microsoft so she has quite
00:06:29.840 a bit of professional AI experience and
00:06:32.639 because I want to get a pulse on what
00:06:34.080 her latest ebook is all about that's
00:06:36.639 what we're going to be using crew aai
00:06:39.080 actually has a builtin rag tool
00:06:42.880 specialized for performing rag against
00:06:46.000 PDFs so let's import
00:06:48.639 it and give this tool to our researcher
00:06:54.520 agent like so
00:07:00.319 and
00:07:01.879 if we look closely at the configuration
00:07:04.879 of this PDF Search tool for performing
00:07:08.800 rag against a particular PDF you can see
00:07:11.440 we're pointing it to the
00:07:14.280 ebook and specifying that we're going to
00:07:18.759 use nomic embed text as our embeddings
00:07:23.120 model if you've never heard of
00:07:24.879 embeddings it's just a fancy term for
00:07:27.840 converting data into a list of numbers
00:07:30.240 so that an AI can more easily work with
00:07:32.400 it it's really not that complicated
00:07:34.759 don't worry about it so we're going to
00:07:37.039 be using AMA as the provider of this
00:07:40.160 embeddings model so let's make sure we
00:07:43.800 have this model downloaded before
00:07:47.159 running our
00:07:50.080 application and the last thing we need
00:07:53.240 to do is customize our
00:07:58.440 prompts so let's update the agents. yo
00:08:03.639 like so you can read through this to see
00:08:06.479 exactly what it's
00:08:07.759 doing we're just making this more
00:08:10.199 appropriate for extracting relevant
00:08:12.879 information from this ebook and we're
00:08:15.280 doing the same thing here we're just
00:08:16.639 customizing these prompts to extract
00:08:20.120 data from this ebook
00:08:23.080 so let's run our crew again now that
00:08:27.159 we've set all this up and see what
00:08:36.200 happens okay so this is interesting it
00:08:39.279 did not extract any data
00:08:42.519 from the
00:08:44.360 ebook let's try one more time and see
00:08:46.440 what
00:08:52.279 happens this
00:08:56.040 is
00:08:57.839 the brief
00:09:00.200 that our multi-agent application
00:09:03.240 generated for
00:09:06.000 us now let's add in agent Ops for
00:09:08.920 monitoring to get started with agent Ops
00:09:11.320 come over to app. agent ops. and sign up
00:09:14.240 if you haven't
00:09:15.959 already once you're signed up come over
00:09:18.399 to the API Keys page and copy one of the
00:09:22.399 API Keys associated with one of the
00:09:25.440 projects in your account into the M file
00:09:29.720 of the crew AI project
00:09:32.320 and we're overriding this AMA config in
00:09:36.360 the crewp file so we don't need these
00:09:38.120 but here is how we add the agent Ops API
00:09:41.480 key we type in all
00:09:43.440 caps agent opscore API unor key equals
00:09:48.760 and then we paste in the API key that we
00:09:50.680 copied after we have the agent Ops API
00:09:53.399 key added to our project let's install
00:09:55.480 agent Ops like so and come over to the
00:09:58.600 main. High script and we're going to
00:10:02.640 add the following code at the top let's
00:10:08.880 import our environment variables like
00:10:13.360 so and then let's import agent
00:10:18.200 Ops on line
00:10:22.600 nine and initialize agent Ops like so
00:10:26.399 and because the homies of crew AI
00:10:30.120 and the homies of agent Ops are so tight
00:10:33.800 that's literally all we have to do
00:10:35.320 they've made it quite easy so if we run
00:10:39.040 our crew AI application
00:10:42.480 again let's see what
00:10:48.240 happens here we can see agent Ops has
00:10:51.639 printed out a
00:10:53.160 link and when our agents have finished
00:10:58.120 generating this brief of the Noel
00:11:02.279 Russell ebook we should see another
00:11:05.480 agent Ops URL printed as
00:11:10.079 well we can see that there was an issue
00:11:12.920 extracting text from the PDF again so
00:11:15.600 let's run this one more time and see
00:11:16.839 what
00:11:25.320 happens let's take a look at how many
00:11:27.680 sessions we just ran 1 two 3 four five
00:11:32.600 six 7 so on attempt 7 the agent was able
00:11:39.480 to correctly use the PDF Search tool the
00:11:45.680 tool we're leveraging for performing rag
00:11:48.480 against this ebook so welcome to the
00:11:52.000 world of sub 10 billion parameter
00:11:56.920 models that gives you a feel for for
00:11:59.800 what agent Ops and crew AI is all about
00:12:04.240 peace
